{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857e5451-c9ed-4a7d-8ab9-7f1810f48f32",
   "metadata": {},
   "source": [
    "# This is the first notebook (preprocessing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ff710-0473-429f-92c8-988da4565d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import utils.utils as utils\n",
    "import utils.process_utils as process_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pykalman import KalmanFilter\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4a053-8a86-4b91-9776-e9091b26f569",
   "metadata": {},
   "source": [
    "## Step 1: Transform Data to Numpy Array (3 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e872905-9d9e-4a1c-86ad-7db8a92fee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = None # Replace with your training data root\n",
    "path_list = [] \n",
    "\n",
    "# find all data paths\n",
    "for root, dirs, files in os.walk(os.path.abspath(DATAPATH)):\n",
    "    files.sort()\n",
    "    for file in files:\n",
    "        path_list.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359f775-f48c-44fc-9bcf-296d44851733",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_type = 'vehicle' # Replace with vehicle, pedestrian or cyclist\n",
    "\n",
    "object_type_id = None\n",
    "if object_type == 'vehicle':\n",
    "    object_type_id = 1\n",
    "elif object_type == 'pedestrian': \n",
    "    object_type_id = 2\n",
    "elif object_type == 'cyclist':\n",
    "    object_type_id = 3\n",
    "    \n",
    "agt_save_path = 'data/' + object_type + '/agt_trajs_json/'\n",
    "ego_save_path = 'data/ego/ego_trajs_json/'\n",
    "if not os.path.exists(agt_save_path):\n",
    "    os.makedirs(agt_save_path)\n",
    "if not os.path.exists(ego_save_path):\n",
    "    os.makedirs(ego_save_path)\n",
    "\n",
    "i_e, i_a = 0, 0\n",
    "for k in tqdm(path_list):\n",
    "    i_ego_sub, i_agt_sub = process_utils.process_raw_data(k, \n",
    "                                                          object_type_id = object_type_id,\n",
    "                                                          ego_save_path = ego_save_path,\n",
    "                                                          agt_save_path = agt_save_path,\n",
    "                                                          save_ego = True,\n",
    "                                                          save_agt = True) \n",
    "    i_e = i_e + i_ego_sub\n",
    "    i_a = i_a + i_agt_sub\n",
    "    \n",
    "print('finish')\n",
    "print('number of ego trajs:', i_e, 'number of agt trajs:', i_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed499ee6-0e56-4359-a37c-cce962c9b064",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing Ego Trajectories (Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901dac8-895b-41a5-84b0-2271ab186e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_LON_MAX, A_LON_MIN = 6, -9.8 #[m/s2], acceleration not in this range will be considered as infeasible\n",
    "DELTA_POS_TOL = 2 #[m], greater distance between measurement and smoothed trajectory will be considered as outlier\n",
    "LEAST_MOVING_D = 0.5 #[m], less distance between start and end points will be considered as not moving object \n",
    "DELTA_T_TOL = 0.5 #[s], trajectory with greater time difference will not be interested "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0614a2-ee14-4a4d-8a68-4867fdc76d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_path_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(os.path.abspath('data/ego/ego_trajs_json/')):\n",
    "    files.sort()\n",
    "    for file in files:\n",
    "        ego_path_list.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5c82b-65c1-43e6-b5b4-a0b31ff0b054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin_num_points_in_traj = 91 # We have 91 sample points in one 9s trajectory\n",
    "num_points_in_trajs = [91, 81, 71, 61, 51,41,31,21,11] # Target Number of points after splitting\n",
    "\n",
    "for num_points_in_traj in num_points_in_trajs:\n",
    "    print('Processing sub-trajectory with {} points'.format(num_points_in_traj))\n",
    "    np.random.seed(7)\n",
    "    posterior_means = np.zeros((len(path_list), num_points_in_traj, 6))\n",
    "    posterior_a_lon = np.zeros((len(path_list), num_points_in_traj))\n",
    "\n",
    "    outlier_idx_acc = []\n",
    "    outlier_idx_time = []\n",
    "    outlier_idx_pos = []\n",
    "    outlier_idx_not_moving = []\n",
    "    outlier_idx = []\n",
    "    start_point_indicies = []\n",
    "    \n",
    "    \n",
    "    # Initializing Kalman Smoother Parameters\n",
    "    R = np.diag([0.005, 0.005, 0.1, 0.1]) # Observation Cov\n",
    "    initial_state_mean = np.zeros(6)\n",
    "    initial_state_covariance = np.diag(np.array([R[0, 0], R[2, 2], 10, R[1, 1], R[3, 3], 10]))\n",
    "\n",
    "    dt = 0.1\n",
    "\n",
    "    observation_matrix = np.array([[1, 0, 0, 0, 0, 0],\n",
    "                                   [0, 0, 0, 1, 0, 0],\n",
    "                                   [0, 1, 0, 0, 0, 0],\n",
    "                                   [0, 0, 0, 0, 1, 0]])\n",
    "\n",
    "    Q = np.kron(np.eye(2), np.array([[(dt**5)/20, (dt**4)/8, (dt**3)/6],\n",
    "                          [(dt**4)/8,  (dt**3)/3, (dt**2)/2],\n",
    "                          [(dt**3)/6,  (dt**2)/2, dt]]).astype(np.float32)) # Process Cov\n",
    "    \n",
    "    parameter = {'R': np.diag(R), 'init_cov':np.diag(initial_state_covariance)}\n",
    "\n",
    "    for idx, path in enumerate(tqdm(ego_path_list)):\n",
    "        T, traj, start_point_idx = utils.extract_traj_data(file_path=path, target_num_of_points=num_points_in_traj , traj_type = 'ego_traj')\n",
    "        start_point_indicies.append(start_point_idx)\n",
    "\n",
    "        dT = T[1:] - T[:-1]\n",
    "\n",
    "        transition_matrices = [np.kron(np.eye(2), np.array([[1, dt, 0.5* (dt**2)], \n",
    "                                                             [0, 1, dt],\n",
    "                                                             [0, 0, 1]])) for dt in dT]\n",
    "\n",
    "        initial_state_mean[1] = traj[0,2] # vx\n",
    "        initial_state_mean[4] = traj[0,3] # vy\n",
    "\n",
    "        # We smooth the measurement\n",
    "        kf = KalmanFilter(transition_matrices = transition_matrices, observation_matrices = observation_matrix, transition_covariance = Q,\n",
    "                      observation_covariance = R, initial_state_mean = initial_state_mean, initial_state_covariance = initial_state_covariance)\n",
    "\n",
    "        smoothed_state_means, smoothed_state_covariances  = kf.smooth(traj)\n",
    "\n",
    "        v_xy = smoothed_state_means[:, [1, 4]]\n",
    "        a_xy = smoothed_state_means[:, [2, 5]]\n",
    "        \n",
    "        # Calculate longitudinal acceleration based on velocity vector\n",
    "        a_lon = np.array([np.dot(a ,v) / np.linalg.norm(v) for a, v in zip(a_xy.reshape(-1,2), v_xy.reshape(-1,2))])\n",
    "        \n",
    "        a_lon = a_lon.reshape(-1, num_points_in_traj)\n",
    "\n",
    "        posterior_means[idx] = smoothed_state_means\n",
    "        posterior_a_lon[idx] = a_lon\n",
    "        \n",
    "        # Find outlier with infeasible acceleration and deceleration\n",
    "        outlier_points_acc = np.argwhere((a_lon > A_LON_MAX) |(a_lon < A_LON_MIN))\n",
    "        if outlier_points_acc.shape[0] > 0:\n",
    "            outlier_idx_acc.append(idx)\n",
    "        \n",
    "        # Find outlier with high deviation between ks outout and measurement\n",
    "        delta_pos_max = np.amax(np.linalg.norm(traj[:,[0,1]] - smoothed_state_means[:, [0,3]], axis=1))\n",
    "        \n",
    "        if delta_pos_max > DELTA_POS_TOL:\n",
    "            outlier_idx_pos.append(idx)\n",
    "            \n",
    "        # Find not moving outlier    \n",
    "        moving_d = np.linalg.norm(traj[-1, :2])\n",
    "        \n",
    "        if moving_d <= LEAST_MOVING_D:\n",
    "            outlier_idx_not_moving.append(idx)\n",
    "\n",
    "        # Find outlier with time issue\n",
    "        if (T[-1] >= ((num_points_in_traj-1) / 10) + DELTA_T_TOL ) | (T[-1] < ((num_points_in_traj-1) / 10) - DELTA_T_TOL):\n",
    "            outlier_idx_time.append(idx)\n",
    "\n",
    "\n",
    "\n",
    "    outlier_idx = set(outlier_idx_acc) | set(outlier_idx_time) | set(outlier_idx_pos) | set(outlier_idx_not_moving)\n",
    "    print('Find {0} outliers, from which {1} acc outlier, {2} time outlier, {3} pos outlier, {4} not moving'.format(len(outlier_idx), len(outlier_idx_acc), len(outlier_idx_time), len(outlier_idx_pos),len(outlier_idx_not_moving)))\n",
    "\n",
    "    \n",
    "    PATH = \"data/ego/ego_trajs_\" + str(num_points_in_traj) + \"_json\"\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    with open(PATH + \"/ego_trajs_outlier_indicies.json\", \"w\") as write_file:\n",
    "        json.dump(list(outlier_idx), write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "    with open(PATH + \"/ego_trajs_outlier_indicies_pos.json\", \"w\") as write_file:\n",
    "        json.dump(list(outlier_idx_pos), write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "    with open(PATH + \"/ego_trajs_outlier_indicies_acc.json\", \"w\") as write_file:\n",
    "        json.dump(outlier_idx_acc, write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "    with open(PATH + \"/ego_trajs_outlier_indicies_time.json\", \"w\") as write_file:\n",
    "        json.dump(outlier_idx_time, write_file, cls=utils.NumpyEncoder)\n",
    "        \n",
    "    with open(PATH + \"/ego_trajs_outlier_indicies_not_moving.json\", \"w\") as write_file:\n",
    "        json.dump(outlier_idx_not_moving, write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "    with open(PATH + \"/ego_trajs_start_point_indicies.json\", \"w\") as write_file:\n",
    "        json.dump(start_point_indicies, write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "    with open(PATH + \"/ego_trajs_filtered_CA.json\", \"w\") as write_file:\n",
    "        json.dump(posterior_means, write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "    with open(PATH + \"/ego_trajs_filtered_a_lon.json\", \"w\") as write_file:\n",
    "        json.dump(posterior_a_lon, write_file, cls=utils.NumpyEncoder)\n",
    "        \n",
    "    with open(PATH + \"/ks_parameter.json\", \"w\") as write_file:\n",
    "        json.dump(parameter, write_file, cls=utils.NumpyEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76432f0c-9516-4802-8b46-2b8edf53c6d4",
   "metadata": {},
   "source": [
    "# Preprocessing Agent Trajectories (Smoothing, 6 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6b72c-8891-4475-a603-c6728b822995",
   "metadata": {},
   "outputs": [],
   "source": [
    "agt_file_path_list = []\n",
    "np.random.seed(7)\n",
    "object_type = 'vehicle'\n",
    "\n",
    "select_file_idx = np.sort(np.random.choice(range(1829161), size=600000, replace=False)) # We randomly choose 60k data from all 1829161 agent trajectories (vehicle) for further processing\n",
    "\n",
    "for root, dirs, files in os.walk(os.path.abspath('data/'+ object_type + '/agt_trajs_json/')):\n",
    "    files.sort()\n",
    "    for idx, file in enumerate(tqdm(files)):\n",
    "        if '.json' not in file or 'checkpoint' in file: # ignore unrelated file\n",
    "            continue\n",
    "        \n",
    "        # When processing vehicle trajs, we only choose 600000 for further processing, else we use all trajs.\n",
    "        if idx in select_file_idx and object_type=='vehicle':\n",
    "            agt_file_path_list.append(os.path.join(root, file))\n",
    "        else:\n",
    "            agt_file_path_list.append(os.path.join(root, file))\n",
    "\n",
    "len(agt_file_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4d876-37d8-49b0-b2ab-cc633316d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_LON_MAX, A_LON_MIN = None, None #[m/s2], acceleration not in this range will be considered as infeasible\n",
    "if object_type =='vechile':\n",
    "    A_LON_MAX, A_LON_MIN = 6, -9.8 \n",
    "elif object_type == 'pedestrian':\n",
    "    A_LON_MAX, A_LON_MIN = 2, -3\n",
    "elif object_type == 'cyclist':\n",
    "    A_LON_MAX, A_LON_MIN = 2, -4\n",
    "    \n",
    "DELTA_POS_TOL = 2 #[m], greater distance between measurement and smoothed trajectory will be considered as outlier\n",
    "LEAST_MOVING_D = 0.5 #[m], less distance between start and end points will be considered as not moving object \n",
    "DELTA_T_TOL = 0.5 #[s], trajectory with greater time difference will not be interested "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9b323-a217-41b3-aa4d-178d2a766f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_num_points_in_traj = 91 # We have 91 sample points in one 9s trajectory\n",
    "num_points_in_trajs = [91,81,71,61,51,41,31,21, 11] # Target Number of points after splitting\n",
    "\n",
    "for num_points_in_traj in num_points_in_trajs:\n",
    "    print('Processing sub-trajectory with {} points'.format(num_points_in_traj))\n",
    "    np.random.seed(7)\n",
    "    posterior_means = np.zeros((len(agt_file_path_list), num_points_in_traj, 6))\n",
    "    posterior_a_lon = np.zeros((len(agt_file_path_list), num_points_in_traj))\n",
    "\n",
    "    outlier_idx_acc = []\n",
    "    outlier_idx_time = []\n",
    "    outlier_idx_pos = []\n",
    "    outlier_idx_not_moving = []\n",
    "    outlier_idx = []\n",
    "    start_point_indicies = []\n",
    "    \n",
    "    out_of_view = 0\n",
    "    \n",
    "    \n",
    "    # Initializing Kalman Smoother Parameters\n",
    "    R = np.diag([0.01, 0.01, 1, 1]) \n",
    "\n",
    "    initial_state_mean = np.zeros(6)\n",
    "    initial_state_covariance = np.diag(np.array([R[0, 0], R[2, 2], 10, R[1, 1], R[3, 3], 10]))\n",
    "\n",
    "    dt = 0.1\n",
    "\n",
    "    observation_matrix = np.array([[1, 0, 0, 0, 0, 0],\n",
    "                                   [0, 0, 0, 1, 0, 0],\n",
    "                                   [0, 1, 0, 0, 0, 0],\n",
    "                                   [0, 0, 0, 0, 1, 0]])\n",
    "    \n",
    "    Q = np.kron(np.eye(2), np.array([[(dt**5)/20, (dt**4)/8, (dt**3)/6],\n",
    "                          [(dt**4)/8,  (dt**3)/3, (dt**2)/2],\n",
    "                          [(dt**3)/6,  (dt**2)/2, dt]]).astype(np.float32)) # Process Cov\n",
    "    \n",
    "        \n",
    "    parameter = {'R': np.diag(R), 'init_cov':np.diag(initial_state_covariance)}\n",
    "    \n",
    "    for idx, path in enumerate(tqdm(agt_file_path_list)):\n",
    "        T, traj, start_point_idx = utils.extract_traj_data(file_path=path, target_num_of_points=num_points_in_traj , traj_type = 'agt_traj')\n",
    "        \n",
    "        start_point_indicies.append(start_point_idx)\n",
    "\n",
    "        dT = T[1:] - T[:-1]\n",
    "\n",
    "        transition_matrices = [np.kron(np.eye(2), np.array([[1, dt, 0.5* (dt**2)], \n",
    "                                                             [0, 1, dt],\n",
    "                                                             [0, 0, 1]])) for dt in dT]\n",
    "\n",
    "        initial_state_mean[1] = traj[0,2]\n",
    "        initial_state_mean[4] = traj[0,3]\n",
    "\n",
    "\n",
    "        kf = KalmanFilter(transition_matrices = transition_matrices, observation_matrices = observation_matrix, transition_covariance = Q,\n",
    "                      observation_covariance = R, initial_state_mean = initial_state_mean, initial_state_covariance = initial_state_covariance)\n",
    "\n",
    "        smoothed_state_means, smoothed_state_covariances  = kf.smooth(traj)\n",
    "\n",
    "        v_xy = smoothed_state_means[:, [1, 4]]\n",
    "        a_xy = smoothed_state_means[:, [2, 5]]\n",
    "\n",
    "        a_lon = np.array([np.dot(a ,v) / np.linalg.norm(v) for a, v in zip(a_xy.reshape(-1,2), v_xy.reshape(-1,2))])\n",
    "\n",
    "        a_lon = a_lon.reshape(-1, num_points_in_traj)\n",
    "\n",
    "        posterior_means[idx] = smoothed_state_means\n",
    "        posterior_a_lon[idx] = a_lon\n",
    "\n",
    "        delta_pos_max = np.amax(np.linalg.norm(traj[:,[0,1]] - smoothed_state_means[:, [0,3]], axis=1))\n",
    "        \n",
    "        moving_d = np.linalg.norm(traj[-1, :2])\n",
    "        \n",
    "\n",
    "        if object_type == 'vehicle':\n",
    "            outlier_points_acc = np.argwhere((a_lon > A_LON_MAX) |(a_lon < A_LON_MIN))\n",
    "            \n",
    "        if outlier_points_acc.shape[0] > 0:\n",
    "            outlier_idx_acc.append(idx)\n",
    "            \n",
    "        if delta_pos_max > DELTA_POS_TOL:\n",
    "            outlier_idx_pos.append(idx)\n",
    "            \n",
    "        if moving_d <= LEAST_MOVING_D:\n",
    "            outlier_idx_not_moving.append(idx)\n",
    "            \n",
    "        if (T[-1] >= ((num_points_in_traj-1) / 10) + DELTA_T_TOL ) | (T[-1] < ((num_points_in_traj-1) / 10) - DELTA_T_TOL):\n",
    "            outlier_idx_time.append(idx)\n",
    "\n",
    "    outlier_idx = set(outlier_idx_acc) | set(outlier_idx_time) | set(outlier_idx_pos) | set(outlier_idx_not_moving)\n",
    "    \n",
    "    # we choose 300000 trajs without outlier for our experiments\n",
    "    if object_type == 'vehicle':\n",
    "        non_outlier_idx = list(set(range(idx+1)) - outlier_idx)\n",
    "        non_outlier_idx = np.sort(np.random.choice(non_outlier_idx, size=300000, replace=False))\n",
    "    \n",
    "\n",
    "    print('Find {0} outliers, from which {1} acc outlier, {2} time outlier, {3} pos outlier, {4} not moving'.format(len(outlier_idx), len(outlier_idx_acc), len(outlier_idx_time), len(outlier_idx_pos),len(outlier_idx_not_moving)))\n",
    "    \n",
    "    \n",
    "    PATH = \"data/\"+ object_type + \"/agt_trajs_\" + str(num_points_in_traj) + \"_json\"\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    with open(PATH + \"/agt_trajs_outlier_indicies.json\", \"w\") as write_file:\n",
    "        json.dump(list(outlier_idx), write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "    with open(PATH + \"/agt_trajs_outlier_indicies_pos.json\", \"w\") as write_file:\n",
    "        json.dump(list(outlier_idx_pos), write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "    with open(PATH + \"/agt_trajs_outlier_indicies_acc.json\", \"w\") as write_file:\n",
    "        json.dump(outlier_idx_acc, write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "    with open(PATH + \"/agt_trajs_outlier_indicies_time.json\", \"w\") as write_file:\n",
    "        json.dump(outlier_idx_time, write_file, cls=utils.NumpyEncoder)\n",
    "        \n",
    "    with open(PATH + \"/agt_trajs_outlier_indicies_not_moving.json\", \"w\") as write_file:\n",
    "        json.dump(outlier_idx_not_moving, write_file, cls=utils.NumpyEncoder)\n",
    "    \n",
    "    if object_type == 'vehicle': # only store the 300000 selected data \n",
    "        with open(PATH + \"/agt_trajs_select_non_outlier_indicies.json\", \"w\") as write_file:\n",
    "            json.dump(select_file_idx[non_outlier_idx], write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "        with open(PATH + \"/agt_trajs_start_point_indicies.json\", \"w\") as write_file:\n",
    "            json.dump(np.array(start_point_indicies)[non_outlier_idx], write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "        with open(PATH + \"/agt_trajs_filtered_CA.json\", \"w\") as write_file:\n",
    "            json.dump(posterior_means[non_outlier_idx], write_file, cls=utils.NumpyEncoder)\n",
    "            \n",
    "        with open(PATH + \"/agt_trajs_filtered_a_lon.json\", \"w\") as write_file:\n",
    "            json.dump(posterior_a_lon[non_outlier_idx], write_file, cls=utils.NumpyEncoder)\n",
    "    else: # store all data \n",
    "        with open(PATH + \"/agt_trajs_start_point_indicies.json\", \"w\") as write_file:\n",
    "            json.dump(start_point_indicies, write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "        with open(PATH + \"/agt_trajs_filtered_CA.json\", \"w\") as write_file:\n",
    "            json.dump(posterior_means, write_file, cls=utils.NumpyEncoder)\n",
    "\n",
    "        with open(PATH + \"/agt_trajs_filtered_a_lon.json\", \"w\") as write_file:\n",
    "            json.dump(posterior_a_lon, write_file, cls=utils.NumpyEncoder)\n",
    "        \n",
    "    with open(PATH + \"/ks_parameter.json\", \"w\") as write_file:\n",
    "        json.dump(parameter, write_file, cls=utils.NumpyEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p38)",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
